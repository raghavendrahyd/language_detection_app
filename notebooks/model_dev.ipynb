{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv \n",
    "df = pd.read_csv(\"../datasets/Language Detection.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10337, 2), Index(['Text', 'Language'], dtype='object'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Language.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a torch dataset.\n",
    "class LanguageDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.text = df[\"Text\"].values\n",
    "        self.label = df[\"Language\"].values\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.label = self.label_encoder.fit_transform(self.label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.text[idx]\n",
    "        label = self.label[idx]\n",
    "        return text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_df = LanguageDataset(df)\n",
    "\n",
    "# split the dataset into train and test\n",
    "num_train = int(len(dataset_df) * 0.8)\n",
    "split_train_, split_valid_ = \\\n",
    "    random_split(dataset_df, [num_train, len(dataset_df) - num_train])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8269, 2068, 10337)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split_train_), len(split_valid_), len(dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"L'apprendimento automatico e il data mining infatti si sovrappongono in modo significativo, ma mentre l'apprendimento automatico si concentra sulla previsione basata su proprietà note apprese dai dati, il data mining si concentra sulla scoperta di proprietà prima sconosciute nei dati.\", 8)\n",
      "('Ich habe versucht, Ihnen zu helfen, konnte aber das Ergebnis nicht erreichen, das Sie sagen können.', 5)\n",
      "('Υπάρχουν τρία κύρια χαρακτηριστικά του σχεδίου της Βικιπαίδειας, τα οποία σε συνδυασμό ορίζουν τον ιστό του στο Διαδίκτυο (World Wide Web) και το κάνουν μοναδικό: H Βικιπαίδεια, όπως και η Nupedia (άλλο ένα σχέδιο ελεύθερης και δωρεάν εγκυκλοπαίδειας), υποστηρίζεται από τον υπέρμαχο του ελεύθερου και δωρεάν λογισμικού Ρίτσαρντ Στόλλμαν και το Ίδρυμα Ελεύθερου Λογισμικού.', 6)\n",
      "('[29] Larry Sanger e Jimmy Wales fundaram a Wikipédia.', 11)\n",
      "('In addition to performing linear classification, SVMs can efficiently perform a non-linear classification using what is called the kernel trick, implicitly mapping their inputs into high-dimensional feature spaces.', 3)\n"
     ]
    }
   ],
   "source": [
    "# check few entries of the dataset\n",
    "for i in range(5):\n",
    "    print(split_train_[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing the text\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[!@#$(),\\n\"%^*?\\:;~`0-9]', ' ', text) # remove punctuations\n",
    "    text = re.sub(r'[[]]', ' ', text) # remove square brackets\n",
    "    text = re.sub(r\"\\s+\",\" \",text) # remove extra spaces\n",
    "    text = re.sub(r\"\\'s\",\" \",text) # remove 's\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NgramTokenizer\n",
    "\n",
    "class NgramTokenizer:\n",
    "    def __init__(self, ngram=1):\n",
    "        self.ngram = ngram\n",
    "\n",
    "    def __call__(self, text):\n",
    "        #preprocess\n",
    "        text = preprocess(text)\n",
    "        # split the text into words\n",
    "        words = text.split()\n",
    "        # create ngrams\n",
    "        ngrams = zip(*[words[i:] for i in range(self.ngram)])\n",
    "        return [\" \".join(ngram) for ngram in ngrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'world', 'how', 'are', 'you']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unigram tokenizer\n",
    "tokenizer = NgramTokenizer(ngram=1)\n",
    "tokenizer(\"Hello world how are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a vocabulary\n",
    "from collections import Counter\n",
    "from torchtext.vocab import vocab\n",
    "\n",
    "def create_vocab(tokenizer, dataset, min_freq=1):\n",
    "    counter = Counter()\n",
    "    for text, _ in dataset:\n",
    "        counter.update(tokenizer(text))\n",
    "\n",
    "    print(f\"Unique tokens in dataset: {len(counter)}\")\n",
    "    print('few of them: ', counter.most_common(10))\n",
    "    return vocab(counter, min_freq=min_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in dataset: 45042\n",
      "few of them:  [('de', 2781), ('a', 1514), ('the', 1298), ('en', 1235), ('la', 1189), (']', 1122), ('[', 1120), ('que', 1010), ('in', 974), ('of', 919)]\n"
     ]
    }
   ],
   "source": [
    "# create a vocab\n",
    "vocab = create_vocab(tokenizer, split_train_,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab) # vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(x,voc=None,unk=0,tokenizer=tokenizer):\n",
    "    v = vocab if voc is None else voc\n",
    "    return [v.get_stoi().get(s,unk) for s in tokenizer(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[27080, 62, 4063, 545, 542, 305]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checkin the encode function\n",
    "encode(\"Hello world how are you, लिए\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample text:\n",
      "L'apprendimento automatico e il data mining infatti si sovrappongono in modo significativo, ma mentre l'apprendimento automatico si concentra sulla previsione basata su proprietà note apprese dai dati, il data mining si concentra sulla scoperta di proprietà prima sconosciute nei dati.\n",
      "\n",
      "BoW vector:\n",
      "tensor([2, 2, 1,  ..., 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "def to_bow(text,bow_vocab_size=vocab_size):\n",
    "    res = torch.zeros(bow_vocab_size,dtype=torch.long)\n",
    "    for i in encode(text):\n",
    "        if i<bow_vocab_size:\n",
    "            res[i] += 1\n",
    "    return res\n",
    "\n",
    "print(f\"sample text:\\n{split_train_[0][0]}\")\n",
    "print(f\"\\nBoW vector:\\n{to_bow(split_train_[0][0])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bowify(b):\n",
    "    # creates a bag of words representation of a batch of text\n",
    "    return (\n",
    "            torch.stack([to_bow(t[0]) for t in b]),\n",
    "            # torch integer tensor of the labels\n",
    "                torch.tensor([t[1] for t in b], dtype=torch.int64)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "data_loader_train = DataLoader(split_train_, batch_size=32, shuffle=True, collate_fn=bowify)\n",
    "data_loader_valid = DataLoader(split_valid_, batch_size=32, shuffle=False, collate_fn=bowify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]])\n",
      "torch.Size([32, 45042])\n",
      "tensor([13,  1,  6,  1, 13,  8,  4, 14, 15,  4, 15, 14, 13,  6,  6, 13,  2, 10,\n",
      "         8, 11, 11,  5, 13, 14, 15,  1,  3,  5,  4,  3,  8,  5])\n",
      "32 32\n"
     ]
    }
   ],
   "source": [
    "# check the dataloader output\n",
    "for text, label in data_loader_train:\n",
    "    print(text)\n",
    "    print(text.shape)\n",
    "    print(label)\n",
    "    print(len(text), len(label))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45042"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets build a pytorch lightning model for classification\n",
    "class LanguageDetectionModel(pl.LightningModule):\n",
    "    def __init__(self, vocab_size, embedding_dim, num_classes):\n",
    "        super(LanguageDetectionModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.fc1 = nn.Linear(embedding_dim, 10)\n",
    "        self.fc2 = nn.Linear(10, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x) # embeddin \n",
    "        x = torch.mean(x, dim=1) # average pooling, dimension 1 is the batch dimension\n",
    "        x = F.relu(self.fc1(x)) # relu activation\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        text, label = batch\n",
    "        label = label.long() # convert to long\n",
    "        logits = self(text)\n",
    "        loss = F.cross_entropy(logits, label) # calculate loss\n",
    "        self.log(\"train_loss\", loss, prog_bar=True) # log the loss\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        text, label = batch\n",
    "        label = label.long()\n",
    "        logits = self(text)\n",
    "        loss = F.cross_entropy(logits, label)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return data_loader_train\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return data_loader_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LanguageDetectionModel(vocab_size=vocab_size, embedding_dim=16, num_classes=17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 45042])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 17])\n",
      "tensor(2.8838, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# one batch of data check\n",
    "for text, label in data_loader_train:\n",
    "    print(text.shape)\n",
    "    print(label.shape)\n",
    "    out = model(text)\n",
    "    print(out.shape)\n",
    "    #validation loss\n",
    "    loss = F.cross_entropy(out, label.long())\n",
    "    print(loss)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=1, log_every_n_steps=5, enable_progress_bar=True, fast_dev_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | embedding | Embedding | 720 K \n",
      "1 | fc1       | Linear    | 170   \n",
      "2 | fc2       | Linear    | 187   \n",
      "----------------------------------------\n",
      "721 K     Trainable params\n",
      "0         Non-trainable params\n",
      "721 K     Total params\n",
      "2.884     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24249db8c2fa44a6bec6b765581e4879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c67b934fdb419b9ca8a8ad659292c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1` reached.\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10337 entries, 0 to 10336\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Text      10337 non-null  object\n",
      " 1   Language  10337 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 161.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text        0\n",
       "Language    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['English', 'Malayalam', 'Hindi', 'Tamil', 'Portugeese', 'French',\n",
       "       'Dutch', 'Spanish', 'Greek', 'Russian', 'Danish', 'Italian',\n",
       "       'Turkish', 'Sweedish', 'Arabic', 'German', 'Kannada'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for unique values\n",
    "df['Language'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nature, in the broadest sense, is the natural...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Nature\" can refer to the phenomena of the phy...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The study of nature is a large, if not the onl...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Although humans are part of nature, human acti...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1] The word nature is borrowed from the Old F...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Language\n",
       "0   Nature, in the broadest sense, is the natural...  English\n",
       "1  \"Nature\" can refer to the phenomena of the phy...  English\n",
       "2  The study of nature is a large, if not the onl...  English\n",
       "3  Although humans are part of nature, human acti...  English\n",
       "4  [1] The word nature is borrowed from the Old F...  English"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets see few entries per language\n",
    "df[df['Language'] == 'English'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3250</th>\n",
       "      <td>Si vous disposez d'ouvrages ou d'articles de r...</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3251</th>\n",
       "      <td>Comment ajouter mes sources ?</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3252</th>\n",
       "      <td>Cette page ou section est en train d'être trad...</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3253</th>\n",
       "      <td>Vous pouvez aider au développement de Wikipédi...</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3254</th>\n",
       "      <td>Le mot nature est un terme polysémique (c’est-...</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text Language\n",
       "3250  Si vous disposez d'ouvrages ou d'articles de r...   French\n",
       "3251                      Comment ajouter mes sources ?   French\n",
       "3252  Cette page ou section est en train d'être trad...   French\n",
       "3253  Vous pouvez aider au développement de Wikipédi...   French\n",
       "3254  Le mot nature est un terme polysémique (c’est-...   French"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df[df['Language'] == 'French'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>विकि-शब्दकोष (एक मुक्त शब्दकोष एवं समानांतर को...</td>\n",
       "      <td>Hindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>[42] अंत में, विकिपीडिया एक पक्ष नहीं लेता है।...</td>\n",
       "      <td>Hindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>बोट्स नामक कंप्यूटर प्रोग्राम के निर्माण के बा...</td>\n",
       "      <td>Hindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>\"\"नहीं, हम नहीं जानते\", जिमी ने कहा.</td>\n",
       "      <td>Hindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>[60] कुछ आलोचकों का दावा है कि विकिपीडिया की ख...</td>\n",
       "      <td>Hindi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text Language\n",
       "1979  विकि-शब्दकोष (एक मुक्त शब्दकोष एवं समानांतर को...    Hindi\n",
       "1980  [42] अंत में, विकिपीडिया एक पक्ष नहीं लेता है।...    Hindi\n",
       "1981  बोट्स नामक कंप्यूटर प्रोग्राम के निर्माण के बा...    Hindi\n",
       "1982               \"\"नहीं, हम नहीं जानते\", जिमी ने कहा.    Hindi\n",
       "1983  [60] कुछ आलोचकों का दावा है कि विकिपीडिया की ख...    Hindi"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df[df['Language'] == 'Hindi'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"Text\"]\n",
    "y = df[\"Language\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Arabic', 'Danish', 'Dutch', 'English', 'French', 'German',\n",
       "       'Greek', 'Hindi', 'Italian', 'Kannada', 'Malayalam', 'Portugeese',\n",
       "       'Russian', 'Spanish', 'Sweedish', 'Tamil', 'Turkish'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label encoding\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = X.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of words on text data\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "\n",
    "X_train = cv.fit_transform(X_train)\n",
    "X_test = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8216, 34527), (2055, 34527))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=150, n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=150, n_jobs=-1, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=150, n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model building\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=150, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy:  0.9982960077896786\n",
      "train classification report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       411\n",
      "           1       1.00      1.00      1.00       339\n",
      "           2       1.00      1.00      1.00       434\n",
      "           3       1.00      1.00      1.00      1092\n",
      "           4       1.00      1.00      1.00       797\n",
      "           5       1.00      1.00      1.00       379\n",
      "           6       1.00      1.00      1.00       293\n",
      "           7       1.00      1.00      1.00        54\n",
      "           8       1.00      1.00      1.00       564\n",
      "           9       0.96      1.00      0.98       296\n",
      "          10       1.00      1.00      1.00       469\n",
      "          11       1.00      1.00      1.00       597\n",
      "          12       1.00      1.00      1.00       569\n",
      "          13       1.00      1.00      1.00       656\n",
      "          14       1.00      1.00      1.00       523\n",
      "          15       1.00      0.98      0.99       378\n",
      "          16       1.00      1.00      1.00       365\n",
      "\n",
      "    accuracy                           1.00      8216\n",
      "   macro avg       1.00      1.00      1.00      8216\n",
      "weighted avg       1.00      1.00      1.00      8216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: ', accuracy_score(y_train, rf.predict(X_train)))\n",
    "\n",
    "print('train classification report: ', classification_report(y_train, rf.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy is {} 0.9318734793187348\n",
      "test classification report is {}               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95       121\n",
      "           1       0.95      0.93      0.94        85\n",
      "           2       0.98      0.92      0.95       108\n",
      "           3       0.98      0.97      0.98       290\n",
      "           4       0.99      0.91      0.95       210\n",
      "           5       0.99      0.93      0.96        86\n",
      "           6       1.00      0.91      0.95        65\n",
      "           7       1.00      0.88      0.93         8\n",
      "           8       0.96      0.92      0.94       130\n",
      "           9       0.41      1.00      0.58        70\n",
      "          10       1.00      0.95      0.97       122\n",
      "          11       0.98      0.92      0.95       139\n",
      "          12       1.00      0.93      0.97       119\n",
      "          13       0.91      0.93      0.92       160\n",
      "          14       0.97      0.94      0.96       150\n",
      "          15       1.00      0.98      0.99        86\n",
      "          16       1.00      0.83      0.91       106\n",
      "\n",
      "    accuracy                           0.93      2055\n",
      "   macro avg       0.95      0.93      0.93      2055\n",
      "weighted avg       0.96      0.93      0.94      2055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('test accuracy is {}', accuracy_score(y_test, y_pred))\n",
    "\n",
    "print('test classification report is {}', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def predict_language(text):\n",
    "    text = preprocess(text)\n",
    "    text = cv.transform([text])\n",
    "    return le.inverse_transform(rf.predict(text))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'English'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for a random sentence\n",
    "predict_language(\"Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'French'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_language(\"Bonjour, comment allez-vous?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hindi'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_language(\"आप कैसे हैं?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> seems pretty good so going ahead and saving to deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;bow&#x27;, CountVectorizer()),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 RandomForestClassifier(n_estimators=150, n_jobs=-1,\n",
       "                                        random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;bow&#x27;, CountVectorizer()),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 RandomForestClassifier(n_estimators=150, n_jobs=-1,\n",
       "                                        random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=150, n_jobs=-1, random_state=42)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('bow', CountVectorizer()),\n",
       "                ('classifier',\n",
       "                 RandomForestClassifier(n_estimators=150, n_jobs=-1,\n",
       "                                        random_state=42))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer()),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=150, random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "pipeline.fit(X, y) # train on entire data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hindi'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick check for a random sentence on the pipeline\n",
    "\n",
    "sample_text = \"आप कैसे हैं?\"\n",
    "\n",
    "#preprocess\n",
    "sample_text = preprocess(sample_text)\n",
    "le.inverse_transform(pipeline.predict([sample_text]))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the pipeline locally. Rewrite if already exists\n",
    "\n",
    "pickle.dump(pipeline, open(\"../app/model/language_detection_pipeline.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the label encoder\n",
    "pickle.dump(le, open(\"../app/model/label_encoder.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('torch_2_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8fb8b680fd183c223b836b79cdcb0f2f0334fe2549f7dc1091ef51ac1f51f680"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
